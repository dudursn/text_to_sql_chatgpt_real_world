{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import pandas as pd\n",
    "import json\n",
    "import time\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# append parent directory to path to import dataset_utils.py\n",
    "# sys.path.append(os.path.join(os.path.dirname(os.getcwd()), \"functions'))\n",
    "\n",
    "# colocar \"\" caso sejo no tecgraf\n",
    "run_environment = \"\"\n",
    "# run_environment = \"\"\n",
    "\n",
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "sys.path.append(os.path.dirname(os.path.dirname(os.getcwd())))\n",
    "dotenv_path = Path(parent_dir)\n",
    "load_dotenv(dotenv_path=dotenv_path)\n",
    "\n",
    "if run_environment == \"pt/\":\n",
    "    from functions.pt.chatgpt_utils import get_openai_function_call, get_openai_response_msg\n",
    "    import functions.pt.gptconfig as gptconfig\n",
    "    gptconfig.engine  = gptconfig.engine_4\n",
    "    \n",
    "else:\n",
    "    from functions.llama_helper import format_prompt, LlamaHelper\n",
    "    from functions.dataset_utils import DatasetEvaluator\n",
    "    from functions.chatgpt_utils import get_openai_function_call, get_openai_response_msg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"role\": \"assistant\",\n",
      "  \"content\": \"How can I assist you today?\",\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 13,\n",
      "    \"completion_tokens\": 7,\n",
      "    \"total_tokens\": 20\n",
      "  }\n",
      "}\n",
      "[-0.010191123001277447, -0.010742533020675182, 0.0006008211639709771, -0.03130415454506874, -0.018774520605802536, 0.03717700392007828, -0.04025958478450775, -0.0129481740295887, 0.008218004368245602, -0.015040875412523746, -0.0025461199693381786, 0.020156366750597954, 0.0037270013708621264, -0.007214836776256561, -0.02519213780760765, 0.0025261894334107637, 0.012569494545459747, -0.009752652607858181, 0.016768183559179306, 0.00037867928040213883, -0.03470562398433685, 0.0075403680093586445, 0.012602712027728558, -0.003142373636364937, -0.023850150406360626, 0.013752036727964878, 0.0068693747743964195, -0.02492639794945717, 0.023903299123048782, -0.005324762314558029, 0.034679047763347626, 0.006205025129020214, 0.006155198905616999, -0.022096268832683563, -0.027955831959843636, -0.01955845206975937, 0.001906683435663581, -0.007865899242460728, 0.012144310399889946, -0.003922984469681978, -0.00027985728229396045, -0.0063843997195363045, 0.012250606901943684, -0.011825422756373882, -0.010470150038599968, 0.00958656519651413, -0.013267061673104763, 0.01567865163087845, -0.05322768911719322, 0.008995293639600277, 0.00715504540130496, 0.027039028704166412, -0.009839017875492573, -0.016515731811523438, 0.003909697290509939, -0.01811017096042633, 0.008224648423492908, 0.020023496821522713, -0.0013353427639231086, 0.007872543297708035, 0.004892935045063496, -0.010994985699653625, -0.02638796716928482, 0.025178849697113037, 0.011938362382352352, -0.007799464277923107, -0.010204410180449486, -0.006105372682213783, 0.01623670384287834, 0.01807030849158764, 0.017937438562512398, 0.012150954455137253, 0.014270229265093803, -0.015120597556233406, 0.0367252454161644, 0.011978222988545895, -0.011001629754900932, -0.02221585065126419, 0.0030128255020827055, -0.0037701840046793222, 0.019545165821909904, -0.006915879435837269, -0.03226081654429436, -0.021485066041350365, 0.01933257281780243, 0.012522989884018898, -0.008609971031546593, 0.00965300016105175, -0.04180087894201279, -0.010755820199847221, -0.0027055637910962105, 0.008902284316718578, 0.029736287891864777, 0.0027371204923838377, -0.027078889310359955, 0.0013635775540024042, 0.022973209619522095, 0.031862206757068634, 0.012662503868341446, -0.03534339740872383, 0.0002285777882207185, 0.016090547665953636, -0.0032519912347197533, -0.008144926279783249, -0.013778611086308956, -0.021524926647543907, -0.0074805766344070435, 0.01949201710522175, 0.027025742456316948, -0.01587795652449131, -0.01914655603468418, 0.026534123346209526, -0.004281733185052872, -0.05290880426764488, -0.009599851444363594, -0.016436008736491203, 0.005367944948375225, -0.0027321376837790012, -0.01041035819798708, -0.01781785674393177, -0.011679266579449177, 0.030639803037047386, 0.01613040827214718, -0.007108540739864111, 0.0166220273822546, 0.023943159729242325, -0.004351489711552858, -0.02535158023238182, -0.00131790351588279, -0.003979454282671213, 0.03117128275334835, 0.024129178375005722, 0.0054177711717784405, 0.008330943994224072, -0.02098016068339348, 0.010390427894890308, -0.03978125378489494, 0.00697567081078887, -0.006304677575826645, -0.010868759825825691, 0.012383476831018925, 0.01416393369436264, -0.013147478923201561, -0.011054777540266514, 0.00961978267878294, 0.018933963030576706, 0.03683154284954071, -0.013273704797029495, -0.007500506937503815, -0.01842905767261982, 0.019704610109329224, -0.059419430792331696, 0.024806814268231392, 0.0003051855892408639, -0.002483006566762924, 0.018747946247458458, -0.004902900196611881, 0.02454107441008091, -0.01380518451333046, 0.015226893126964569, -0.011293943040072918, -0.028513886034488678, 0.019678035750985146, -0.02007664553821087, 0.023743854835629463, 0.031064987182617188, 0.019478730857372284, -0.006264816969633102, -0.01395134162157774, -0.00839073583483696, -0.023610984906554222, 0.03789450228214264, -0.03611404448747635, 0.020913725718855858, 0.0030161472968757153, 0.019930487498641014, 0.012988034635782242, 0.003597453236579895, -0.028248146176338196, -0.004829821642488241, -0.03366923704743385, -0.0074938638135790825, 0.014748561196029186, 0.008570109494030476, -0.003982775844633579, 0.021578075364232063, 0.025843199342489243, -0.005710084922611713, 0.004275089595466852, 0.006683357059955597, 0.014735274016857147, 0.005075631197541952, 0.0017023958498612046, -0.0048630391247570515, -0.6611607074737549, -0.02474037930369377, 0.003640635870397091, -0.008948788978159428, 0.011685909703373909, 0.031091561540961266, 0.02877962589263916, -0.0020893795881420374, -0.010058253072202206, -0.07174975425004959, -0.015532493591308594, 0.017764708027243614, -0.01298139151185751, -0.0032071478199213743, 0.004364776890724897, -0.007520437706261873, 0.014535969123244286, 0.007885829545557499, -0.00045923166908323765, 0.022029833868145943, -0.02149835415184498, -0.0072347670793533325, -0.016595453023910522, -0.0015662042424082756, 0.026853011921048164, 0.012011440470814705, 0.008105065673589706, -0.005324762314558029, -0.018601788207888603, 0.005580536555498838, -0.03236711397767067, 0.022654321044683456, 0.016316426917910576, -0.006792974658310413, 0.047647152096033096, -0.023597698658704758, -0.013977915979921818, 0.0452023483812809, 0.02127247489988804, 0.030692951753735542, 0.01594439148902893, 0.005407806020230055, 0.02399630844593048, 0.007473933044821024, 0.005932642146945, 0.00913480669260025, 0.020940300077199936, -0.011048134416341782, 0.02415575087070465, -0.008012056350708008, -0.004052532836794853, -0.02909851260483265, -0.007779533974826336, 4.645256922231056e-05, 0.02370399422943592, 0.019040260463953018, 0.03547626733779907, 0.00719490647315979, -0.011101282201707363, 0.014974440447986126, -0.023238949477672577, -0.0008595022954978049, -0.024793528020381927, -0.020023496821522713, -0.008038630709052086, 0.015771659091114998, -0.032287392765283585, -0.015386336483061314, -0.0035476270131766796, -0.01543948519974947, 0.0010006766533479095, 0.0029796080198138952, -0.017312951385974884, 0.01743253320455551, 0.01892067678272724, 0.006171807646751404, 0.019279425963759422, 0.0018253005109727383, 0.0015628824476152658, 0.0029131730552762747, 0.02201654575765133, -0.006161842495203018, -0.007095254026353359, 0.001868483261205256, 0.027690092101693153, -0.0030178080778568983, -0.02758379653096199, -0.02431519515812397, -0.011466674506664276, -0.0025677112862467766, 0.02386343851685524, 0.015957677736878395, -0.02803555317223072, -0.004879647865891457, -0.011260725557804108, 0.013559375889599323, -0.01408421155065298, 0.009772582910954952, 0.011758987791836262, -0.010549872182309628, -0.015040875412523746, -0.012111092917621136, 0.007520437706261873, 0.02347811497747898, 0.027025742456316948, 0.009393903426826, -0.011845353990793228, 0.014761848375201225, 0.0301348976790905, -0.024647369980812073, 0.003333374159410596, 0.005387875251471996, -0.03010832518339157, -0.03507765755057335, 0.017738133668899536, -0.02072770707309246, 0.010144618339836597, 0.0002112424117513001, 0.027955831959843636, -0.021073170006275177, 0.004514255560934544, -0.013845046050846577, 0.010616307146847248, 0.010417002253234386, 0.01178556215018034, 0.016661887988448143, -0.012655859813094139, -0.01574508659541607, 0.006367790978401899, -0.018801093101501465, -0.012310397811233997, 0.011247439309954643, 0.026666993275284767, 0.00042892072815448046, 0.019505305215716362, -0.018415771424770355, 0.014124073088169098, 0.011871927417814732, 0.0011401900555938482, -0.010895333252847195, -0.029736287891864777, -0.00942712090909481, -0.01537305023521185, 0.00965300016105175, 0.004231906961649656, -0.04692965745925903, -0.026760002598166466, 0.016675176098942757, -0.019943775609135628, 0.0058296676725149155, 0.00588613748550415, -0.01278872974216938, -0.007779533974826336, 0.02745092660188675, 0.009400546550750732, 0.0044976468198001385, -0.014124073088169098, -0.013120904564857483, -0.007547011598944664, -0.0024514500983059406, 0.012562851421535015, 0.020581550896167755, -0.006377756129950285, 0.0040292805060744286, 0.007719742599874735, -0.0252851452678442, -0.011107925325632095, 0.028540458530187607, -0.0232123751193285, -0.01752554252743721, 0.016316426917910576, 0.009639712981879711, -0.0016625348944216967, 0.0031473562121391296, -0.01506744883954525, -0.0007407498196698725, -0.01529332809150219, -0.011858640238642693, 0.013738749548792839, 0.011685909703373909, 0.018575215712189674, 0.019837480038404465, -0.020103219896554947, 0.0020893795881420374, 0.021139604970812798, 0.01521360594779253, -0.014190508052706718, 0.030825821682810783, -0.009367329068481922, 0.006799618247896433, -0.010184479877352715, 0.0038399407640099525, -0.011878571473062038, 0.00913480669260025, -0.02098016068339348, 0.005474240984767675, -0.011566326953470707, -0.002576015656813979, -0.0028384337201714516, 0.024102604016661644, 0.026946019381284714, 0.0004455294692888856, 0.01574508659541607, -0.00292978179641068, -0.009274320676922798, -0.057665545493364334, 0.016449296846985817, -0.015054162591695786, 0.01163940504193306, 0.02040882036089897, 0.004524220712482929, -0.019837480038404465, -0.0035742009058594704, -0.015014301054179668, 0.02043539471924305, 0.006673391908407211, 0.006650139577686787, -0.011778919026255608, -0.004633838310837746, -0.011519822292029858, 0.015479345805943012, 0.0035509485751390457, 0.012815304100513458, -0.0036074183881282806, -0.013200626708567142, -0.007141758222132921, 0.013585949316620827, 0.017126932740211487, -0.00636114738881588, -0.006739826872944832, 0.0023767107632011175, 0.014482821337878704, -0.008795988745987415, 0.008184786885976791, -0.00044594466453418136, 0.010828898288309574, 0.02082071639597416, -0.02657398395240307, 0.030506934970617294, -0.005012517794966698, -0.0040492108091712, 0.03850570321083069, 0.003790114540606737, -0.01178556215018034, 0.035555992275476456, 0.010795680806040764, 0.0182696133852005, 0.007447359152138233, -0.016369573771953583, 0.009500198997557163, -0.005298187956213951, 0.011878571473062038, -0.0006585365626960993, -0.007865899242460728, 0.008443883620202541, -0.04549466073513031, 0.019345860928297043, 0.011147786863148212, 0.006414295639842749, -0.01387161947786808, 0.041535139083862305, 0.002232214668765664, 0.012695721350610256, 0.007301202043890953, 0.01571851223707199, -0.01063623744994402, -0.01282194722443819, -0.01537305023521185, -0.014203794300556183, -0.01535976305603981, -0.003756897058337927, 0.0007208193419501185, 0.009812443517148495, 0.001214098883792758, -0.004706916864961386, -0.027012454345822334, -0.010257557965815067, -0.007367637008428574, 0.029922306537628174, -0.014070924371480942, -0.0071882628835737705, -0.040631622076034546, 0.038612000644207, 0.00910158921033144, -0.017246516421437263, -0.024594223126769066, -0.024049455299973488, 0.01535976305603981, -0.005872850771993399, 0.01296810433268547, 0.018442345783114433, 0.011712484061717987, -0.0003682988171931356, -0.012177527882158756, -0.019957061856985092, 0.0005202688043937087, 0.031702764332294464, -0.017033923417329788, -0.017339523881673813, -0.01565207727253437, -0.00931418128311634, -0.022561313584446907, -0.026587272062897682, -0.009108233265578747, 0.008038630709052086, 0.012735581956803799, -0.00357752270065248, -0.00704874936491251, 0.015399623662233353, -0.027039028704166412, -0.008789345622062683, -0.0031407128553837538, 0.008955433033406734, 0.006417617201805115, -0.005736658815294504, 0.014190508052706718, -0.023305384442210197, -0.026720141991972923, 0.019159842282533646, -0.004434533417224884, -0.017273088917136192, -0.028301293030381203, -0.009845660999417305, -0.0014300125185400248, 0.0016409435775130987, 0.0003307215520180762, -0.0030726168770343065, 0.014535969123244286, 0.019425582140684128, 0.0029945557471364737, -0.027105463668704033, -0.002984590595588088, 0.013134191744029522, 0.009075015783309937, -0.00850367546081543, 0.004919508937746286, 0.007068679668009281, -0.0036306707188487053, 0.00816485658288002, 0.011473317630589008, 0.010868759825825691, -0.011300587095320225, 0.02098016068339348, -0.024275334551930428, -0.01842905767261982, -0.005862885154783726, 0.01186528429389, 0.017857717350125313, 0.01416393369436264, -0.005065665580332279, 0.029311105608940125, 0.018801093101501465, 0.01401777658611536, -0.024886535480618477, -0.008982006460428238, 0.024567648768424988, 0.005799772217869759, 0.002157475333660841, -0.013738749548792839, -0.016821332275867462, -0.020515115931630135, -0.005613754037767649, 0.02373056858778, -0.0065803830511868, 0.013360070995986462, 0.006317964754998684, 0.006484052166342735, -0.01714021898806095, 0.01159290038049221, -0.02877962589263916, -0.0008316826424561441, 0.027822962030768394, -0.0006327930022962391, -0.03699098527431488, 0.022694183513522148, -0.01943887025117874, -0.033934976905584335, -0.012496416456997395, -0.002253805985674262, 0.03308461233973503, 0.02305293083190918, 0.001998031511902809, -0.0038565495051443577, 0.008882354013621807, -0.008603326976299286, -0.00350776594132185, 0.022720756009221077, -0.017180081456899643, -0.016887767240405083, -0.02007664553821087, -0.006616922095417976, -0.00700888829305768, -0.032420262694358826, 0.013213913887739182, -0.00238501513376832, -0.012071232311427593, -0.020608125254511833, 0.013659028336405754, 0.022840339690446854, 0.010124688036739826, -0.012237319722771645, -0.01170584000647068, 0.0009093285189010203, 0.01840248331427574, 0.0009259372600354254, 0.012237319722771645, 0.007593516260385513, -0.0021873710211366415, 0.011838709935545921, -0.01949201710522175, 0.02108645625412464, -0.015917817130684853, -0.007726385723799467, 0.00954006053507328, 0.0076134465634822845, -0.015240180306136608, 0.03473219648003578, 0.001076246378943324, 0.0022405190393328667, -0.003913019318133593, 0.027955831959843636, -0.009998461231589317, 0.0035874878522008657, -0.01668846234679222, -0.0016434348654001951, -0.037070706486701965, -0.0006087103392928839, -0.01943887025117874, -0.007792820688337088, 0.004680342972278595, -0.013738749548792839, 0.023079505190253258, -0.032446835190057755, -0.010835542343556881, 0.012410050258040428, -0.018801093101501465, 0.014482821337878704, -0.00025681263650767505, 0.013240487314760685, 0.015226893126964569, -0.02489982359111309, 0.022853625938296318, -0.01571851223707199, -0.0262285228818655, 0.028434162959456444, -0.035874877125024796, 0.03281887248158455, 0.024129178375005722, 0.01408421155065298, 0.006949096918106079, 0.011340447701513767, -0.01729966327548027, -0.011891857720911503, 0.005161996465176344, 0.03236711397767067, 0.007620090153068304, -0.010855472646653652, -0.008284439332783222, -0.03534339740872383, 0.0015811520861461759, -0.00639436487108469, 0.023783715441823006, -0.016794757917523384, -0.01581152155995369, -0.01664860174059868, 0.011034847237169743, 0.0028949035331606865, -0.015691937878727913, -0.017831142991781235, -0.026055792346596718, 0.005630362778902054, 0.026308244094252586, -0.010536585003137589, 0.015665363520383835, 0.0028234857600182295, -0.00019307660113554448, -0.002288684481754899, -0.006610278505831957, 0.005739980842918158, -0.004793282598257065, -0.03345664590597153, -0.030374065041542053, 0.019638175144791603, 0.026294957846403122, 0.03728330135345459, 0.010629593394696712, 0.016210131347179413, -0.004331559408456087, -0.017498968169093132, 0.003044381970539689, -0.013021252118051052, 0.032739147543907166, -0.0117722749710083, 0.037522464990615845, 0.012549564242362976, 0.0301348976790905, 0.008862423710525036, -0.01885424181818962, 0.013426505960524082, 0.023517975583672523, -0.021458491683006287, 0.010177835822105408, -0.009978530928492546, -0.016994062811136246, -0.011147786863148212, -0.0024248759727925062, 0.0023252235259860754, -0.0102642010897398, -0.006988957989960909, -0.0039694891311228275, 0.026853011921048164, -0.005377910099923611, 0.004856395535171032, 0.00113769865129143, 0.0209535863250494, -0.021551501005887985, 0.03234053775668144, -0.013619166798889637, -0.0027653551660478115, -0.007905760779976845, -0.012443267740309238, -0.006719896104186773, -0.00354430521838367, 0.00022753974189981818, 0.020714420825242996, 0.010649524629116058, -0.005002552643418312, 0.009785870090126991, -0.002728816121816635, 0.017312951385974884, 0.01583809405565262, -0.004427890293300152, 0.019345860928297043, -0.019903915002942085, -0.01817660592496395, -0.017964012920856476, 0.0007897455943748355, -0.05745295435190201, -0.01293488685041666, 0.007945621386170387, -0.011254082433879375, 0.022162703797221184, -0.014708700589835644, -0.025816624984145164, 0.012808660045266151, -0.0026740070898085833, 0.011805492453277111, -0.018163317814469337, 0.024567648768424988, 0.034253865480422974, -0.024301908910274506, -0.010111400857567787, 0.01617026887834072, -0.02280047908425331, -0.01807030849158764, 0.004696951713413, 0.024859962984919548, -0.02075428143143654, 0.009081658907234669, 0.02670685388147831, -0.009559990838170052, 0.003027773229405284, -0.012463198974728584, -0.005135422572493553, 0.00903515424579382, 0.03598117455840111, -0.013924768194556236, -0.020289236679673195, -0.01432337798178196, 0.04081764072179794, -0.012715651653707027, -0.009075015783309937, -0.007912403903901577, -0.006643495988100767, -0.003753575263544917, 0.008450526744127274, -0.00921452883630991, 0.027796387672424316, 0.02088715136051178, -0.020834004506468773, -0.010789037682116032, 0.01282194722443819, -0.014894718304276466, -0.0001813466806197539, 0.00016286945901811123, 0.03151674568653107, 0.001735613332130015, 0.014442960731685162, 0.00971943512558937, 0.023238949477672577, 0.0016608739970251918, -0.0013918124604970217, -0.004281733185052872, 0.018508780747652054, -0.014814996160566807, -0.009114876389503479, -0.0006174299051053822, 0.018030447885394096, 0.02377042919397354, 0.0014615691034123302, -0.007287915330380201, -0.01055651530623436, -0.03643293306231499, -0.006178451236337423, 0.011360378004610538, 0.013898193836212158, -0.0161968432366848, -0.007832681760191917, -0.012104449793696404, -0.009971887804567814, -0.04177430272102356, 0.0004974317853339016, 0.0005439362139441073, 0.04445827752351761, -0.036618951708078384, -0.012263894081115723, -0.001423369045369327, 0.01590452902019024, 0.004530864302068949, -0.009646356105804443, -0.0006747300503775477, -0.00708196684718132, -0.012635929509997368, 0.018216466531157494, -0.04283726215362549, 0.008742840960621834, -0.011778919026255608, 0.0075403680093586445, -0.0024132500402629375, -0.032446835190057755, 0.026268383488059044, -0.01626327820122242, -0.019797617569565773, 0.0015529171796515584, -0.004716882016509771, 0.007533724419772625, 0.0040292805060744286, -0.013599236495792866, 0.021232614293694496, 0.015040875412523746, -0.0009367329766973853, -0.03547626733779907, -0.021139604970812798, -0.0001711738295853138, -0.019040260463953018, -0.014429673552513123, 0.031410448253154755, -0.02063469961285591, -0.008902284316718578, 0.016449296846985817, -0.00015529172378592193, 0.018229752779006958, -0.011679266579449177, -0.007586872670799494, -0.012449911795556545, 0.017791282385587692, -0.007899116724729538, -0.013120904564857483, 0.012516346760094166, -0.006231599487364292, -0.022229138761758804, 0.0075536551885306835, 0.008875710889697075, -0.01571851223707199, -0.005321440286934376, 0.006955740507692099, -0.003313443623483181, -0.002561067696660757, -0.025750190019607544, -0.011001629754900932, -0.012522989884018898, -0.028885921463370323, -0.0051254574209451675, -0.010862115770578384, -0.004135576542466879, -0.0009408851619809866, 0.0030908866319805384, -0.03566228598356247, -0.01678147166967392, 0.011579614132642746, -0.0054177711717784405, 0.010211053304374218, -0.012861808761954308, 0.02515227533876896, 0.01687448099255562, -0.021392056718468666, 0.0005240057362243533, -0.0015147171216085553, 0.015851382166147232, 0.008590040728449821, 0.007958908565342426, 0.006766400765627623, 0.0166220273822546, 0.005367944948375225, 0.012237319722771645, -0.012768799439072609, -0.028221571817994118, -0.014934578910470009, 0.024195613339543343, 0.0037801493890583515, 0.001926613855175674, 0.019771045073866844, -0.030347490683197975, -0.009566633962094784, -0.021285761147737503, 0.008091778494417667, 0.01949201710522175, -0.016661887988448143, 0.015731798484921455, -0.024195613339543343, -0.005793128628283739, -0.006726539693772793, 0.015333188697695732, -0.003677175147458911, 0.022189276292920113, -0.004926152527332306, -0.002076092641800642, -0.011446744203567505, -0.018615076318383217, -0.0031656259670853615, -0.01290166936814785, -0.006494017317891121, 0.014934578910470009, 0.0253781545907259, -0.005005874205380678, 0.018309475854039192, 0.00271220738068223, -0.003919662907719612, -0.010343923233449459, 0.002019622828811407, -0.02111303061246872, 0.011247439309954643, 0.011061420664191246, 0.00018269613792654127, -0.005862885154783726, -0.024567648768424988, 0.004693630151450634, -0.012489772401750088, 0.015917817130684853, -0.005583858583122492, -0.004560760222375393, -0.04589327052235603, 0.01581152155995369, 0.014682126231491566, -0.0034579397179186344, 0.002293667057529092, -0.02133890986442566, 0.00524504017084837, 0.006982314400374889, -0.016821332275867462, 0.013898193836212158, -0.007673237938433886, -0.006590348202735186, 0.012815304100513458, 0.00588613748550415, -0.024036169052124023, -0.004138898104429245, 0.0064574782736599445, 0.017445821315050125, 0.03374896198511124, 0.20515115559101105, 0.01041035819798708, -0.01380518451333046, 0.059738315641880035, 0.0018917354755103588, 0.019452156499028206, 0.027344629168510437, 0.010151262395083904, 0.0039694891311228275, 0.010583089664578438, -0.0034745484590530396, -0.0007727216579951346, -0.009699503891170025, -0.00045964689343236387, 0.00033466611057519913, -0.009905452840030193, -0.025325007736682892, -0.008835849352180958, -0.0037834709510207176, -0.038133665919303894, 0.00010546550038270652, -0.020289236679673195, -0.008689693175256252, 0.006261494942009449, 0.02438163012266159, 0.0126425726339221, -0.0039694891311228275, 0.005514101590961218, 0.030347490683197975, 0.003966167103499174, 0.002811859827488661, -0.0016766523476690054, 0.015266753733158112, -0.005294866394251585, -0.013240487314760685, -0.010118044912815094, -0.00791904702782631, -0.02072770707309246, 0.03829311206936836, 0.01542619802057743, -0.0019382400205358863, 0.008576753549277782, -0.008291083388030529, -0.016156982630491257, -0.0004542490351013839, 0.02140534482896328, -0.01583809405565262, -0.01872137188911438, 0.015891242772340775, 0.010463505983352661, -0.03149017319083214, -0.0052882228046655655, 0.011274012736976147, 0.02745092660188675, 0.01691434159874916, -0.000288992072455585, 0.009114876389503479, -0.012449911795556545, -0.010822255164384842, -0.006616922095417976, 0.00527825765311718, 0.026308244094252586, -0.028699902817606926, 0.017671698704361916, -0.01668846234679222, -0.006404330022633076, -0.03611404448747635, -0.02489982359111309, 0.015758372843265533, -0.012443267740309238, 0.005374588537961245, -0.010317349806427956, -0.016063973307609558, -0.004859717562794685, -0.031118135899305344, -0.03544969484210014, 0.021803954616189003, 0.02454107441008091, 0.022136129438877106, 0.016741611063480377, -0.007527081295847893, 0.00043556420132517815, -0.014522682875394821, -0.008237935602664948, -0.0029696428682655096, -0.029204808175563812, 0.015333188697695732, -0.01937243528664112, 0.0007054562447592616, 0.0038831233978271484, 0.004537507891654968, -0.011008272878825665, -0.0011335464660078287, -0.006567095872014761, 0.01565207727253437, 0.017552116885781288, 0.007341063115745783, 0.01849549263715744, -0.006454156246036291, 0.006175129674375057, -0.03151674568653107, -0.016834618523716927, 0.016077261418104172, 0.017990587279200554, -0.00628806883469224, 0.02036895975470543, -0.0013370035449042916, 0.0091813113540411, 0.013366714119911194, 0.01557235512882471, -0.007287915330380201, -0.0129481740295887, -0.0021840492263436317, -0.010835542343556881, 0.015014301054179668, -0.021325621753931046, -0.000703380152117461, -0.018150031566619873, 0.018827667459845543, 0.0005713406717404723, 0.014934578910470009, -0.013180696405470371, 0.0024946327321231365, -0.014788422733545303, 0.011499891988933086, -0.01091526448726654, -0.012841877527534962, 0.012815304100513458, 0.006038937717676163, -0.03313775733113289, 0.001301294774748385, -0.004417924676090479, 0.03688469156622887, -0.02149835415184498, -0.02302635833621025, 0.04071134328842163, 0.016967488452792168, -0.013320209458470345, -0.0019913879223167896, -0.02618866227567196, -0.0039562019519507885, -0.01260935515165329, 0.01283523440361023, 0.0066335308365523815, -0.007473933044821024, -0.023079505190253258, 0.013054469600319862, -0.0021491709630936384, -0.030214620754122734, -0.028965642675757408, -0.01401777658611536, 0.0049826218746602535, -0.0013519515050575137, 0.00791904702782631, 0.03746931627392769, -0.0104767931625247, -0.04873668774962425, 0.002600928768515587, 0.0017389351269230247, 0.0022870234679430723, -0.018694797530770302, 0.008915571495890617, 0.040631622076034546, -0.029869157820940018, -0.03167618811130524, 0.012682434171438217, -0.1717742383480072, 0.026042504236102104, -0.010649524629116058, -0.006706609390676022, 0.012157597579061985, -0.01188521459698677, -0.002292006043717265, 0.004587334115058184, -0.00813163910061121, 0.0080984216183424, 0.0013345122570171952, -0.0029115122742950916, -0.031224431470036507, 0.002268753945827484, -0.001010641804896295, 0.011320517398416996, -0.012150954455137253, 0.015054162591695786, 0.03475877270102501, 0.011679266579449177, 0.023199088871479034, -0.018083596602082253, 0.024687230587005615, -0.006895949132740498, 0.019678035750985146, 0.0037967581301927567, -0.016994062811136246, 0.025471163913607597, -0.011426812969148159, -0.02314594015479088, -0.01989062689244747, -0.0019199703820049763, 0.015226893126964569, 0.0142436558380723, 0.03175591304898262, 0.019133267924189568, -0.018535353243350983, -0.00931418128311634, -0.02289348840713501, 0.03967496007680893, -0.010696028359234333, 0.0072347670793533325, 0.004334880970418453, -0.011287299916148186, -0.017180081456899643, 0.04089736193418503, 0.0062083471566438675, -0.001359425368718803, 0.0011443422408774495, 0.0007785346824675798, 0.017538828775286674, 0.0024531108792871237, 0.0037635406479239464, -0.0038798016030341387, 0.011486604809761047, 0.016529018059372902, 0.011453387327492237, -0.013499584048986435, 0.008968719281256199, -0.00292646000161767, -0.0025677112862467766, -0.019930487498641014, -0.00839073583483696, 0.014575830660760403, 0.005547319073230028, 0.004789960570633411, -0.007367637008428574, -0.0004148032749071717, -0.039887551218271255, 0.01438981294631958, 0.006663426756858826, -0.02395644597709179, -0.008822563104331493, -0.033190906047821045, 0.020315811038017273, -0.0007490541902370751, -0.027796387672424316, 0.019000397995114326, 0.014057638123631477, -0.01655559241771698, -0.023783715441823006, 0.029284531250596046, -0.00690259225666523, -0.015957677736878395, 0.005627041216939688, 0.03744274377822876, -0.014788422733545303, 0.0039030539337545633, 0.003235382493585348, -0.02715861238539219, 0.006683357059955597, -0.0387980155646801, -0.0018767876317724586, -0.023531263694167137, 0.0030775994528084993, 0.005324762314558029, -0.0010754158720374107, -0.006082120817154646, -0.007261341437697411, 0.011260725557804108, 0.01978433132171631, 0.02266760915517807, -0.021803954616189003, 0.02447463944554329, 0.030347490683197975, 0.028992217034101486, 0.011911788024008274, 0.020488541573286057, 0.02923138253390789, 0.021299049258232117, -0.022348720580339432, 0.025976069271564484, 0.024394918233156204, 0.027145324274897575, -0.006115338299423456, 0.004916186910122633, 0.009447051212191582, -0.024806814268231392, 0.024501213803887367, -0.00712182791903615, 0.04979964718222618, -0.008802631869912148, 0.007454002741724253, 0.00704874936491251, -0.019545165821909904, -0.02395644597709179, -0.06239571422338486, 0.004298341926187277, 0.007307845633476973, 0.00900193676352501, 0.014921292662620544, -0.00462387315928936, 0.0004903730587102473, 0.0284873116761446, -0.012250606901943684, 0.03151674568653107, -0.020196227356791496, -0.01091526448726654, 0.002483006566762924, -0.023199088871479034, 0.03194192796945572, 0.014482821337878704, -0.00012747208529617637, -0.024859962984919548, -0.018123457208275795, 0.009593208320438862, -0.0002070902264676988, -0.0031340692657977343, -0.006563774310052395, -0.018787806853652, -0.006480730604380369, -0.008709623478353024, -0.027477499097585678, 0.021963398903608322, 0.018415771424770355, 0.015027588233351707, 0.01998363621532917, -0.025072554126381874, 0.01933257281780243, -0.023557838052511215, -0.004148863255977631, -0.020515115931630135, -0.014775135554373264, 0.0018983790650963783, 0.0030726168770343065, -0.0035908096469938755, -0.0044411770068109035, -0.008995293639600277, -0.004348168149590492, -0.03895746171474457, 0.010131331160664558, -0.004457785747945309, -0.010722602717578411, -0.005102205090224743, -0.006779687944799662, -0.022773904725909233, -0.0013021252816542983, -0.008463813923299313, -0.0035376616287976503, -0.008124995976686478, 0.04459114745259285, -0.020169654861092567, 0.011307230219244957, 0.018615076318383217, -0.02939082682132721, -0.02474037930369377, 0.006553808692842722, 0.007832681760191917, -0.013134191744029522, 0.032606277614831924, -0.02124590054154396, 0.00971943512558937, -0.01565207727253437, -0.021458491683006287, 0.010144618339836597, -0.011486604809761047, -0.012695721350610256, 0.031118135899305344, -0.019704610109329224, 0.005739980842918158, -0.015240180306136608, -0.009746008552610874, -0.0342804379761219, 0.00827779620885849, 0.03308461233973503, -0.0429435595870018, -0.03210137411952019, -0.00946033839136362, 0.001868483261205256, -0.007772890385240316, 0.0091813113540411, 0.024368343874812126, -0.004285054747015238, -0.0070553929544985294, 0.010536585003137589, -0.013373357243835926, -0.006570417433977127, 0.022401869297027588, 0.00903515424579382, -0.009925383143126965, -0.01985076628625393, 0.007507150527089834, -0.0003873988753184676, -0.009128163568675518, 0.02014308050274849, 0.012091162614524364, -0.0018950572703033686, -0.014057638123631477, -0.07020846754312515, 0.015612215735018253, -0.007314489223062992, -0.013738749548792839, 0.014801708981394768, 0.006454156246036291, -0.01282194722443819, 0.0007199888932518661, -0.003037738613784313, -0.005673545878380537, -0.007912403903901577, 0.004278411623090506, 0.0046271951869130135, -0.025856487452983856, -0.01268907729536295, -0.003447974566370249, 0.022348720580339432, 0.0033001566771417856, 0.022295573726296425, -0.005364622920751572, 0.004431211855262518, 0.003313443623483181, 0.012018084526062012, 0.0091813113540411, -0.027477499097585678, 0.010603019967675209, 0.0008192260866053402, 0.0042618028819561005, -0.01949201710522175, -0.02343825437128544, 0.021737519651651382, -0.0161038339138031, -0.004786639008671045, 0.04762057960033417, -0.024554360657930374, -0.028407588601112366, -0.009726078249514103, 0.015625502914190292, 0.008477101102471352, 0.003730323165655136, -0.020807430148124695, -0.011978222988545895, 0.013433149084448814, -0.019040260463953018, -0.009985174983739853, -0.015200318768620491, -0.00014003243995830417, 0.003922984469681978, 0.019345860928297043, 0.015266753733158112, 0.008224648423492908, 0.024208899587392807, -0.0014673821860924363, -0.0183626227080822, 0.001214098883792758, -0.05538018420338631, 0.018229752779006958, 0.006563774310052395, 0.010423645377159119, 0.0043946728110313416, 0.02862018160521984, 0.010064896196126938, -0.010290775448083878, -0.0022039797622710466, 0.0027421030681580305, 0.0027321376837790012, -0.0022023189812898636, 0.0025743546430021524, 0.017552116885781288, -0.05147380754351616, -0.03911690413951874, 0.01270900759845972, 0.022880200296640396, 0.0068228705786168575, 0.014735274016857147, -0.014256943017244339, 0.0055938237346708775, 0.003255313029512763, -0.0017190045909956098, 0.041216250509023666, 0.018322762101888657, -0.009028511121869087, -0.025657182559370995, 0.025138989090919495, 0.003042721189558506, 0.007367637008428574, 0.003484513610601425, 0.008623258210718632, -0.007062036544084549, 0.005294866394251585, -0.02451450005173683, -0.006523913238197565, -0.0011028203880414367, 0.0028018944431096315, -0.022680895403027534, -0.001963153015822172, 0.010417002253234386, -0.03481191769242287, 0.0062681385315954685, 0.03659237548708916, -0.006929166615009308, -0.002559406915679574, 0.014230368658900261, -0.02525857277214527, -0.04097708314657211, 0.008888998068869114, -0.022348720580339432, -0.01029741857200861, 0.004779995419085026, -0.0016633652849122882, 0.02050182968378067, -0.007872543297708035, -0.0017422568053007126, 0.021617935970425606, -0.014695413410663605, -0.0052284314297139645, -0.012536277063190937, -0.015266753733158112, -0.019119981676340103, 0.025231998413801193, 0.013326853513717651, 0.01642272248864174, 0.006464121863245964, -0.005929320119321346, -0.012443267740309238, 0.007281271740794182, 0.015731798484921455, -0.004896256607025862, 0.007487220223993063, 0.0161038339138031, 0.008942145854234695, -0.007108540739864111, -0.006829514168202877, -0.010596375912427902, -0.009858948178589344, 0.0007876695017330348, 0.011141142807900906, 0.014230368658900261, 0.02862018160521984, 0.11129184812307358, -0.009307538159191608, -0.02063469961285591, 0.011513179168105125, -0.0007689846679568291, -0.002479685004800558, 0.01646258309483528, 0.002660720143467188, 0.01044357568025589, 0.0006610278505831957, 0.005670223850756884, -0.00700888829305768, 0.010868759825825691, 0.009779226034879684, -0.03834626078605652, -0.009746008552610874, -0.01949201710522175, 0.026201948523521423, -0.034360162913799286, -0.012728938832879066, 0.014416386373341084, 0.0020113184582442045, 0.004610586445778608, -0.004949404392391443, -0.0025693720672279596, -0.005201857537031174, 0.020382246002554893, 0.0016899392940104008, 0.004593977704644203, -0.008855780586600304, 0.012994678691029549, -0.005454310216009617, -0.013267061673104763, -0.01409749872982502, -0.0011152769438922405, -0.02237529493868351, -0.010217697359621525, -0.010423645377159119, 0.0026441114023327827, 0.014682126231491566, -0.004079106729477644, 0.037575613707304, -0.017777996137738228, -0.01784443110227585, 0.044245682656764984, 0.000723310629837215, 0.006769722327589989, -0.017791282385587692, 0.010603019967675209]\n"
     ]
    }
   ],
   "source": [
    "print(get_openai_response_msg([{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"gpt-4\"\n",
    "# model = \"gpt-3.5-turbo\" # \"gpt-3.5-turbo-16k\" ou \"llama2\"\n",
    "dataset_name = \"mondial\" # \"mondial\" \n",
    "queries_filename = f\"results/queries_{dataset_name}_{model}.json\"\n",
    "start_index = 0 # índice da primeira instância do dataset a ser avaliada\n",
    "end_index = 99 # índice da última instância do dataset avaliada\n",
    "# índices: use 0 e 99 para o dataset inteiro, use o mesmo número nos dois para só um exemplo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classe Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Stage:\n",
    "    def __init__(self,\n",
    "                 model=\"llama2\", \n",
    "                 system_message=\"You are a helpful assistant\"):\n",
    "        self.system_message = system_message\n",
    "        self.messages = [\n",
    "            {\"role\": \"system\", \"content\": system_message},\n",
    "            ]\n",
    "        self.model = model\n",
    "        self.functions = {}\n",
    "        self.max_function_depth = 8\n",
    "        self.function_call = \"auto\"\n",
    "        self.token_usage = {\n",
    "            \"completion_tokens\": 0,\n",
    "            \"prompt_tokens\": 0,\n",
    "            \"total_tokens\": 0\n",
    "        }\n",
    "\n",
    "    def run(self, msg_content, return_function_arguments=True, model=None, log=False):\n",
    "        if model is None:\n",
    "            model = self.model\n",
    "        response_message = self.get_response({\"role\": \"user\", \"content\": msg_content}, model=model, log=log)\n",
    "\n",
    "        if not return_function_arguments:\n",
    "            return response_message\n",
    "        \n",
    "        if \"function_call\" in response_message:\n",
    "            return json.loads(response_message[\"function_call\"][\"arguments\"])\n",
    "        return response_message\n",
    "\n",
    "    def get_response(self, message, model=None, log=False):\n",
    "        if model is None:\n",
    "            model=self.model\n",
    "        if model == \"llama2\":\n",
    "            return\n",
    "        self.messages.append(message)\n",
    "\n",
    "        if self.functions:\n",
    "            response_message = get_openai_function_call(\n",
    "                messages=self.messages,\n",
    "                temperature=0,\n",
    "                max_tokens=1000,\n",
    "                functions=list(self.functions[func_name]['info'] for func_name in self.functions),\n",
    "                function_call=self.function_call #,\n",
    "                #model=model\n",
    "            )\n",
    "        else:\n",
    "            response_message = get_openai_response_msg(\n",
    "                messages=self.messages,\n",
    "                temperature=0,\n",
    "                max_tokens=1000 #,\n",
    "                #model=model\n",
    "            )\n",
    "\n",
    "        if log:\n",
    "            with open(f\"prompt_chain_log{model}.txt\", 'a') as f:\n",
    "                f.write(str(response_message))\n",
    "\n",
    "        self.messages.append(response_message)\n",
    "\n",
    "        token_usage = response_message[\"usage\"]\n",
    "        self.token_usage[\"completion_tokens\"] += token_usage[\"completion_tokens\"]\n",
    "        self.token_usage[\"prompt_tokens\"] += token_usage[\"prompt_tokens\"]\n",
    "        self.token_usage[\"total_tokens\"] += token_usage[\"total_tokens\"]\n",
    "\n",
    "        return response_message\n",
    "\n",
    "    def add_function(self, func_info, func_callback = None):\n",
    "        self.functions[func_info[\"name\"]] = {\"callback\": func_callback, \"info\": func_info}\n",
    "\n",
    "    def reset_history(self):\n",
    "        self.messages = [\n",
    "            {\"role\": \"system\", \"content\": self.system_message},\n",
    "        ]\n",
    "        self.token_usage = {\n",
    "            \"completion_tokens\": 0,\n",
    "            \"prompt_tokens\": 0,\n",
    "            \"total_tokens\": 0\n",
    "        }\n",
    "\n",
    "    def print(self, print_system_message=False):\n",
    "        for message in self.messages:\n",
    "            if message['role'] == \"system\" and not print_system_message:\n",
    "                continue\n",
    "            if \"content\" in message:\n",
    "                print(f\"[{message['role']}]: {message['content']}\")\n",
    "            if \"function_call\" in message:\n",
    "                print(f\"[function call: {message['function_call']['name']}]: {message['function_call']['arguments']}\")\n",
    "\n",
    "    def print_functions(self):\n",
    "        print(list(self.functions[func_name]['info'] for func_name in self.functions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_json(text):\n",
    "    \"\"\"\n",
    "    Find and extract JSON object from strings containing a single JSON object surrounded by other text.\n",
    "    \"\"\"\n",
    "    first_bracket = text.index(\"{\")\n",
    "    last_bracket = len(text) - text[::-1].index(\"}\")\n",
    "    json_string = text[first_bracket:last_bracket]\n",
    "    return json.loads(json_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LlamaStage():\n",
    "    def __init__(self, api_url,\n",
    "                 system_message=\"Você é um assistente prestativo e educado.\"):\n",
    "        self.helper = LlamaHelper(api_url, system_message)\n",
    "\n",
    "    def run(self, msg_content):\n",
    "        response = self.helper.generate_response(msg_content)\n",
    "        return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definição das etapas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_stages_gpt(prompts):\n",
    "    global stage_1, stage_2, stage_3, stage_4\n",
    "    with open(prompts[0], 'r', encoding=\"utf8\") as f:\n",
    "        system_message_1 = f.read()\n",
    "\n",
    "        stage_1 = Stage(system_message=system_message_1)\n",
    "\n",
    "        stage_1.add_function({\n",
    "                            \"name\": \"return_entities\",\n",
    "                                \"description\": \"Returns the list of entities to be used in the query to the system\",\n",
    "                                \"parameters\": {\n",
    "                                    \"type\": \"object\",\n",
    "                                    \"properties\": {\n",
    "                                        \"reasoning\": {\n",
    "                                            \"type\": \"string\",\n",
    "                                            \"description\": \"Reasoning behind choice of entities\"\n",
    "                                        },\n",
    "                                        \"entities\": {\n",
    "                                            \"type\": \"array\",\n",
    "                                            \"description\": \"List of entities\",\n",
    "                                            \"items\": {\n",
    "                                                \"type\": \"string\",\n",
    "                                            }\n",
    "                                        },\n",
    "                                    },\n",
    "                                    \"required\": [\"reasoning\", \"entities\"],\n",
    "                                },\n",
    "                            })\n",
    "        stage_1.function_call = {\"name\": \"return_entities\"}\n",
    "    \n",
    "    with open(prompts[1], 'r', encoding=\"utf8\") as f:\n",
    "        system_message_2 = f.read()\n",
    "\n",
    "        stage_2 = Stage(system_message=system_message_2)\n",
    "\n",
    "        stage_2.add_function({\n",
    "                            \"name\": \"return_properties\",\n",
    "                                \"description\": \"Returns the list of properties to be used in the query to the system\",\n",
    "                                \"parameters\": {\n",
    "                                    \"type\": \"object\",\n",
    "                                    \"properties\": {\n",
    "                                        \"reasoning\": {\n",
    "                                            \"type\": \"string\",\n",
    "                                            \"description\": \"Reasoning behind choice of properties\"\n",
    "                                        },\n",
    "                                        \"entity_properties\": {\n",
    "                                            \"type\": \"array\",\n",
    "                                            \"description\": \"List of objects containing entity names and their properties to be included in the query to the system\",\n",
    "                                            \"items\": {\n",
    "                                                \"type\": \"object\",\n",
    "                                                \"properties\": {\n",
    "                                                    \"entity\": {\n",
    "                                                        \"type\": \"string\",\n",
    "                                                        \"description\": \"Entity name\"\n",
    "                                                    },\n",
    "                                                    \"properties\": {\n",
    "                                                        \"type\": \"array\",\n",
    "                                                        \"description\": \"List of included properties corresponding to the entity\",\n",
    "                                                        \"items\": {\n",
    "                                                            \"type\": \"string\"\n",
    "                                                        }\n",
    "                                                    }\n",
    "                                                }\n",
    "                                            }\n",
    "                                        },\n",
    "                                    },\n",
    "                                    \"required\": [\"reasoning\", \"entity_properties\"],\n",
    "                                },\n",
    "                            })\n",
    "\n",
    "        stage_2.function_call = {\"name\": \"return_properties\"}\n",
    "\n",
    "    with open(prompts[2], 'r', encoding=\"utf8\") as f:\n",
    "        system_message_3 = f.read()\n",
    "\n",
    "        stage_3 = Stage(system_message=system_message_3)\n",
    "\n",
    "        stage_3.add_function({\n",
    "                            \"name\": \"return_queries\",\n",
    "                                \"description\": \"Returns the list of possible keyword queries to the user\",\n",
    "                                \"parameters\": {\n",
    "                                    \"type\": \"object\",\n",
    "                                    \"properties\": {\n",
    "                                        \"reasoning\": {\n",
    "                                            \"type\": \"string\",\n",
    "                                            \"description\": \"Reasoning behind query strings\"\n",
    "                                        },\n",
    "                                        \"queries\": {\n",
    "                                            \"type\": \"array\",\n",
    "                                            \"description\": \"List of query strings\",\n",
    "                                            \"items\": {\n",
    "                                                \"type\": \"string\"\n",
    "                                            }\n",
    "                                        },\n",
    "                                    },\n",
    "                                    \"required\": [\"reasoning\", \"queries\"],\n",
    "                                },\n",
    "                            })\n",
    "\n",
    "        stage_3.function_call = {\"name\": \"return_queries\"}\n",
    "\n",
    "    with open(prompts[3], 'r', encoding=\"utf8\") as f:\n",
    "        system_message_4 = f.read()\n",
    "\n",
    "        stage_4 = Stage(system_message=system_message_4)\n",
    "\n",
    "        stage_4.add_function({\n",
    "                            \"name\": \"return_query\",\n",
    "                                \"description\": \"Returns the final query string to the system\",\n",
    "                                \"parameters\": {\n",
    "                                    \"type\": \"object\",\n",
    "                                    \"properties\": {\n",
    "                                        \"reasoning\": {\n",
    "                                            \"type\": \"string\",\n",
    "                                            \"description\": \"Reasoning behind choice of best query\"\n",
    "                                        },\n",
    "                                        \"query_string\": {\n",
    "                                            \"type\": \"string\",\n",
    "                                            \"description\": \"Final query string\",\n",
    "                                        },\n",
    "                                    },\n",
    "                                    \"required\": [\"reasoning\", \"query_string\"],\n",
    "                                },\n",
    "                            })\n",
    "\n",
    "        stage_4.function_call = {\"name\": \"return_query\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Llama 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_stages_llama(prompts):\n",
    "    global stage_1, stage_2, stage_3, stage_4\n",
    "\n",
    "    with open(\"llama.json\", 'r') as f:\n",
    "        api_url = json.load(f)[\"API_URL\"]\n",
    "\n",
    "    with open(prompts[0], 'r', encoding=\"utf8\") as f:\n",
    "        system_message_1 = f.read()\n",
    "\n",
    "        stage_1 = LlamaStage(api_url, system_message=system_message_1)\n",
    "    \n",
    "    with open(prompts[1], 'r', encoding=\"utf8\") as f:\n",
    "        system_message_2 = f.read()\n",
    "\n",
    "        stage_2 = LlamaStage(api_url, system_message=system_message_2)\n",
    "\n",
    "    with open(prompts[2], 'r', encoding=\"utf8\") as f:\n",
    "        system_message_3 = f.read()\n",
    "\n",
    "        stage_3 = LlamaStage(api_url, system_message=system_message_3)\n",
    "\n",
    "    with open(prompts[3], 'r', encoding=\"utf8\") as f:\n",
    "        system_message_4 = f.read()\n",
    "\n",
    "        stage_4 = LlamaStage(api_url, system_message=system_message_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funções auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_properties(properties_json):\n",
    "    s = \"Entity - Property: Description\\n\"\n",
    "    for prop in properties_json:\n",
    "        entity_name = prop['entity']\n",
    "        prop_name = prop['property']\n",
    "        if ' ' in prop_name:\n",
    "            prop_name = f'\"{prop_name}\"'\n",
    "        if ' ' in entity_name:\n",
    "            entity_name = f'\"{entity_name}\"'\n",
    "        if \"description\" in prop:\n",
    "            s += f\"{entity_name} - {prop_name}: {prop['description']}\\n\"\n",
    "        else:\n",
    "            s += f\"{entity_name} - {prop_name}\\n\"\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entities_info(entities, include_description=True):\n",
    "    df = pd.DataFrame()\n",
    "    for entity in entities:\n",
    "        df = pd.concat([df, db_info[db_info[\"entity\"] == entity]])\n",
    "    if not include_description:\n",
    "        df = df.drop(columns=\"description\")\n",
    "    return format_properties(json.loads(df.to_json(orient='records', force_ascii=False)))\n",
    "# json.loads(db_info[db_info[\"entity\"] == \"País\"].to_json(orient='records'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_properties_info(entity_properties, include_description=True):\n",
    "    properties = []\n",
    "    for property_list in entity_properties:\n",
    "        entity = property_list[\"entity\"]\n",
    "        for prop in property_list[\"properties\"]:\n",
    "            properties.append((entity, prop))\n",
    "    df = pd.DataFrame()\n",
    "    for prop in properties:\n",
    "        df = pd.concat([df, db_info[(db_info[\"entity\"] == prop[0]) & (db_info[\"property\"] == prop[1])]])\n",
    "    if not include_description:\n",
    "        df = df.drop(columns=\"description\")\n",
    "    return format_properties(json.loads(df.to_json(orient='records', force_ascii=False)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definição do \"pipeline\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def question_to_query_gpt(user_query, verbose=False, model=None, log=True):\n",
    "    token_usage = {\n",
    "        \"completion_tokens\": 0,\n",
    "        \"prompt_tokens\": 0,\n",
    "        \"total_tokens\": 0\n",
    "    }\n",
    "\n",
    "    stage_1.reset_history()\n",
    "    if log:\n",
    "        with open(f\"prompt_chain_log{model}.txt\", 'a') as f:\n",
    "            f.write(f\"\\nStage 1 - Query: {user_query}\\n\")\n",
    "    stage_1_response = stage_1.run(user_query, model=model, log=True)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"\\n### Stage 1\")\n",
    "        stage_1.print()\n",
    "\n",
    "    token_usage[\"completion_tokens\"] += stage_1.token_usage[\"completion_tokens\"]\n",
    "    token_usage[\"prompt_tokens\"] += stage_1.token_usage[\"prompt_tokens\"]\n",
    "    token_usage[\"total_tokens\"] += stage_1.token_usage[\"total_tokens\"]\n",
    "\n",
    "    entities = stage_1_response['entities']\n",
    "    entity_info = get_entities_info(entities)\n",
    "\n",
    "    ### Stage 2\n",
    "\n",
    "    stage_2_input = \\\n",
    "    f\"\"\"\n",
    "####\n",
    "Busca do usuário: {user_query}\n",
    "Entidades a serem utilizadas: {entities}\n",
    "Descrição de suas propriedades:\n",
    "{entity_info}\n",
    "####\n",
    "\"\"\"\n",
    "\n",
    "    if log:\n",
    "        with open(f\"prompt_chain_log{model}.txt\", 'a') as f:\n",
    "            f.write(f\"\\nStage 2 - Query: {user_query}\\n\")\n",
    "    try:\n",
    "        stage_2.reset_history()\n",
    "        stage_2_response = stage_2.run(stage_2_input, model=model, log=True)\n",
    "    except:\n",
    "        stage_2.reset_history()\n",
    "        if verbose:\n",
    "            print(\"Error, trying shorter prompt\")\n",
    "        if log:\n",
    "            with open(f\"prompt_chain_log{model}.txt\", 'a') as f:\n",
    "                f.write(\"\\nError, trying shorter prompt\\n\")\n",
    "        short_entity_info = get_entities_info(entities, include_description=False)\n",
    "        stage_2_input = \\\n",
    "    f\"\"\"\n",
    "####\n",
    "Busca do usuário: {user_query}\n",
    "Entidades a serem utilizadas: {entities}\n",
    "Descrição de suas propriedades:\n",
    "{short_entity_info}\n",
    "####\n",
    "\"\"\"\n",
    "        if verbose:\n",
    "            print(stage_2_input)\n",
    "        stage_2_response = stage_2.run(stage_2_input, model=model, log=True)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"\\n### Stage 2\")\n",
    "        stage_2.print()\n",
    "\n",
    "    token_usage[\"completion_tokens\"] += stage_2.token_usage[\"completion_tokens\"]\n",
    "    token_usage[\"prompt_tokens\"] += stage_2.token_usage[\"prompt_tokens\"]\n",
    "    token_usage[\"total_tokens\"] += stage_2.token_usage[\"total_tokens\"]\n",
    "\n",
    "    entity_properties = stage_2_response['entity_properties']\n",
    "\n",
    "    ### Stage 3\n",
    "\n",
    "    stage_3_input = \\\n",
    "    f\"\"\"\n",
    "####\n",
    "Busca do usuário: {user_query}\n",
    "Entidades a serem utilizadas: {entities}\n",
    "Propriedades a serem utilizadas: {get_properties_info(entity_properties)}\n",
    "####\n",
    "\"\"\"\n",
    "\n",
    "    if log:\n",
    "        with open(f\"prompt_chain_log{model}.txt\", 'a') as f:\n",
    "            f.write(f\"\\nStage 3 - Query: {user_query}\\n\")\n",
    "    try:\n",
    "        stage_3.reset_history()\n",
    "        stage_3_response = stage_3.run(stage_3_input, model=model, log=True)\n",
    "    except:\n",
    "        stage_3.reset_history()\n",
    "        if verbose:\n",
    "            print(\"Error, trying shorter prompt\")\n",
    "        if log:\n",
    "            with open(f\"prompt_chain_log{model}.txt\", 'a') as f:\n",
    "                f.write(\"\\nError, trying shorter prompt\\n\")\n",
    "        stage_3_input = \\\n",
    "    f\"\"\"\n",
    "####\n",
    "Busca do usuário: {user_query}\n",
    "Entidades a serem utilizadas: {entities}\n",
    "Propriedades a serem utilizadas: {get_properties_info(entity_properties, include_desctiption=False)}\n",
    "####\n",
    "\"\"\"\n",
    "        stage_3_response = stage_3.run(stage_3_input, model=model, log=True)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"\\n### Stage 3\")\n",
    "        stage_3.print()\n",
    "\n",
    "    token_usage[\"completion_tokens\"] += stage_3.token_usage[\"completion_tokens\"]\n",
    "    token_usage[\"prompt_tokens\"] += stage_3.token_usage[\"prompt_tokens\"]\n",
    "    token_usage[\"total_tokens\"] += stage_3.token_usage[\"total_tokens\"]\n",
    "\n",
    "    queries = stage_3_response['queries']\n",
    "\n",
    "    ### Stage 4\n",
    "\n",
    "    stage_4_input = \\\n",
    "f\"\"\"\n",
    "####\n",
    "Busca do usuário:\n",
    "{user_query}\n",
    "Consultas possíveis:\n",
    "{queries}\n",
    "####\n",
    "\"\"\"\n",
    "\n",
    "    stage_4.reset_history()\n",
    "    if log:\n",
    "        with open(f\"prompt_chain_log{model}.txt\", 'a') as f:\n",
    "            f.write(f\"\\nStage 4 - Query: {user_query}\\n\")\n",
    "    stage_4_response = stage_4.run(stage_4_input, model=model, log=True)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"\\n### Stage 4\")\n",
    "        stage_4.print()\n",
    "\n",
    "    query_string = stage_4_response['query_string']\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Query: {query_string}\")\n",
    "    \n",
    "    token_usage[\"completion_tokens\"] += stage_4.token_usage[\"completion_tokens\"]\n",
    "    token_usage[\"prompt_tokens\"] += stage_4.token_usage[\"prompt_tokens\"]\n",
    "    token_usage[\"total_tokens\"] += stage_4.token_usage[\"total_tokens\"]\n",
    "\n",
    "    return query_string, token_usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Llama 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def question_to_query_llama(user_query, verbose=False, model=None):\n",
    "    stage_1_input = json.dumps({\n",
    "        \"user_input\": user_query\n",
    "    })\n",
    "    stage_1_response = stage_1.run(stage_1_input)\n",
    "    stage_1_json = extract_json(stage_1_response)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"\\n\\n### Stage 1\")\n",
    "        print(f\"Input:\\n{stage_1_input}\\nOutput:\\n{stage_1_json}\")\n",
    "\n",
    "    entities = stage_1_json['entities']\n",
    "    entity_info = get_entities_info(entities)\n",
    "\n",
    "    ### Stage 2\n",
    "\n",
    "    stage_2_input = json.dumps({\n",
    "        \"user_input\": user_query,\n",
    "        \"entities\": entities,\n",
    "        \"properties\": entity_info\n",
    "    })\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"\\nEntities extracted from 1:\\n{entities}\")\n",
    "        print(f\"Stage 2 input:\\n{stage_2_input}\")\n",
    "\n",
    "    stage_2_response = stage_2.run(stage_2_input)\n",
    "    if verbose:\n",
    "        print(f\"Stage 2 response:\\n{stage_2_response}\")\n",
    "        \n",
    "    stage_2_json = extract_json(stage_2_response)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"\\n\\n### Stage 2\")\n",
    "        print(f\"Input:\\n{stage_2_input}\\nOutput:\\n{stage_2_json}\")\n",
    "\n",
    "    entity_properties = stage_2_json['properties']\n",
    "\n",
    "    ### Stage 3\n",
    "\n",
    "    stage_3_input = json.dumps({\n",
    "        \"user_input\": user_query,\n",
    "        \"entities\": entities,\n",
    "        \"properties\": entity_properties\n",
    "    })\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Properties extracted from 2:\\n{entity_properties}\")\n",
    "        print(f\"Stage 3 input:\\n{stage_3_input}\")\n",
    "\n",
    "    stage_3_response = stage_3.run(stage_3_input)\n",
    "    if verbose:\n",
    "        print(f\"Stage 3 response:\\n{stage_3_response}\")\n",
    "\n",
    "    stage_3_json = extract_json(stage_3_response)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"\\n### Stage 3\")\n",
    "        print(f\"Input:\\n{stage_3_input}\\nOutput:\\n{stage_3_json}\")\n",
    "\n",
    "    queries = stage_3_json['queries']\n",
    "\n",
    "    ### Stage 4\n",
    "\n",
    "    stage_4_input = json.dumps({\n",
    "        \"user_input\": user_query,\n",
    "        \"queries\": queries\n",
    "    })\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Queries extracted from 3:\\n{queries}\")\n",
    "        print(f\"Stage 4 input:\\n{stage_4_input}\")\n",
    "\n",
    "    stage_4_response = stage_3.run(stage_4_input)\n",
    "    if verbose:\n",
    "        print(f\"Stage 4 response:\\n{stage_4_response}\")\n",
    "\n",
    "    stage_4_json = extract_json(stage_4_response)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"\\n### Stage 4\")\n",
    "        print(f\"Input:\\n{stage_4_input}\\nOutput:\\n{stage_4_json}\")\n",
    "\n",
    "    final_query = stage_4_json['query']\n",
    "    \n",
    "    return final_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def question_to_query(user_query, prompts, verbose=False, model=\"llama2\"):\n",
    "    if \"gpt\" in model:\n",
    "        init_stages_gpt(prompts)\n",
    "        return question_to_query_gpt(user_query, verbose=verbose, model=model)\n",
    "    elif model == \"llama2\":\n",
    "        init_stages_llama(prompts)\n",
    "        return question_to_query_llama(user_query, verbose=verbose), None\n",
    "    return \"\", None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avaliação "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geração de consultas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_name = \"mondial\"\n",
    "# model = \"gpt-3.5-turbo\"\n",
    "# model = \"llama2\"\n",
    "\n",
    "\n",
    "if dataset_name == \"mondial\":\n",
    "    dataset_file_path = \"../../datasets/mondial/mondial_dataset.json\"\n",
    "    dataset_tables_path = \"../../datasets/mondial/result_tables/\"\n",
    "    db_connection_file = \"../../datasets/mondial_db_connection.json\"\n",
    "\n",
    "    prompt_dir = \"prompts_mondial/\"\n",
    "\n",
    "    db_info = pd.read_json('db_info_mondial.json')\n",
    "\n",
    "if \"gpt\" in model:\n",
    "    prompts = [\n",
    "        f\"{prompt_dir}prompt1.txt\",\n",
    "        f\"{prompt_dir}prompt2.txt\",\n",
    "        f\"{prompt_dir}prompt3.txt\",\n",
    "        f\"{prompt_dir}prompt4.txt\"\n",
    "    ]\n",
    "elif model == \"llama2\":\n",
    "    prompts = [\n",
    "        f\"{prompt_dir}prompt1_llama.txt\",\n",
    "        f\"{prompt_dir}prompt2_llama.txt\",\n",
    "        f\"{prompt_dir}prompt3_llama.txt\",\n",
    "        f\"{prompt_dir}prompt4_llama.txt\"\n",
    "    ]\n",
    "\n",
    "with open(dataset_file_path, 'r', encoding=\"utf8\") as f:\n",
    "    dataset = json.load(f)[\"dataset\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_queries(start_index, end_index, id_list=None, model=None, verbose=False, save_filename=None, override=True, delay=0):\n",
    "    if save_filename:\n",
    "        try:\n",
    "            with open(save_filename, 'r', encoding=\"utf8\") as f:\n",
    "                queries = json.load(f)\n",
    "        except:\n",
    "            queries = {}\n",
    "\n",
    "        if save_filename[-5:] == \".json\":\n",
    "            tokens_filename = save_filename[:-5] + \"_tokens\" + \".json\"\n",
    "        else:\n",
    "            tokens_filename = save_filename + \"_tokens.json\"\n",
    "        \n",
    "        try:\n",
    "            with open(tokens_filename, 'r', encoding=\"utf8\") as f:\n",
    "                queries_tokens = json.load(f)\n",
    "        except:\n",
    "            queries_tokens = {}\n",
    "    else:\n",
    "        queries = {}\n",
    "    for i in range(start_index, end_index + 1):\n",
    "        dataset_instance = dataset[i]\n",
    "        if not override and dataset_instance[\"id\"] in queries.keys():\n",
    "            continue\n",
    "        if id_list is not None and dataset_instance[\"id\"] not in id_list:\n",
    "            continue\n",
    "        question = dataset_instance[\"question\"]\n",
    "        time_elapsed = 0\n",
    "        try:\n",
    "            start = time.time()\n",
    "            query, token_usage = question_to_query(question, prompts, verbose=verbose, model=model)\n",
    "            end = time.time()\n",
    "            time_elapsed = end - start\n",
    "        except Exception as exception:\n",
    "            print(\"Error generating query.\")\n",
    "            print(f\"ID: {dataset_instance['id']}\\nQuery: {question}\")\n",
    "            print(f\"Exception: {str(exception)}\")\n",
    "            query = \"\"\n",
    "            token_usage = {\n",
    "                \"completion_tokens\": 0,\n",
    "                \"prompt_tokens\": 0,\n",
    "                \"total_tokens\": 0,\n",
    "            }\n",
    "        queries[dataset_instance[\"id\"]] = query\n",
    "        queries_tokens[dataset_instance[\"id\"]] = token_usage\n",
    "        queries_tokens[dataset_instance[\"id\"]][\"time_elapsed\"] = time_elapsed\n",
    "        if save_filename:\n",
    "            with open(save_filename, 'w', encoding=\"utf8\") as f:\n",
    "                json.dump(queries, f, indent=4, ensure_ascii=False)\n",
    "            with open(tokens_filename, 'w', encoding=\"utf8\") as f:\n",
    "                json.dump(queries_tokens, f, indent=4, ensure_ascii=False)\n",
    "        time.sleep(delay)\n",
    "            \n",
    "    return queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = [\"16\", \"21\", \"23\", \"36\", \"37\", \"45\", \"47\", \"50\", \"52\", \"53\", \"78\", \"79\", \"80\", \"81\", \"83\", \"84\", \"85\", \"86\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# queries_filename=\"queries_mondial_llama2_13b.json\"\n",
    "queries_filename = \"queries_mondial_gpt4_100_2.json\"\n",
    "queries = generate_queries(start_index, end_index, id_list=ids, model=model, verbose=True, save_filename=queries_filename, override=True, delay=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avaliação dos resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval_filename = queries_filename\n",
    "eval_filename = \"queries_mondial_gpt35_100.json\"\n",
    "eval_dataset_name = \"mondial\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if eval_dataset_name == \"mondial\":\n",
    "    eval_dataset_file_path = \"../../datasets/mondial/mondial_dataset.json\"\n",
    "    eval_dataset_tables_path = \"../../datasets/mondial/result_tables/\"\n",
    "    eval_db_connection_file = \"../../datasets/mondial_db_connection.json\"\n",
    "\n",
    "    eval_db_info = pd.read_json('db_info_mondial.json')\n",
    "\n",
    "\n",
    "\n",
    "with open(eval_dataset_file_path, 'r', encoding=\"utf8\") as f:\n",
    "    eval_dataset = json.load(f)[\"dataset\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = DatasetEvaluator(dataset_file_path=eval_dataset_file_path,\n",
    "                             dataset_tables_path=eval_dataset_tables_path,\n",
    "                             db_connection_file=eval_db_connection_file,\n",
    "                             dataset_name=eval_dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(eval_filename, 'r', encoding=\"utf8\") as f:\n",
    "    queries_raw = json.load(f)\n",
    "queries = []\n",
    "for instance_id, query in queries_raw.items():\n",
    "    queries.append({\n",
    "        \"id\": instance_id,\n",
    "        # \"query_string\": query\n",
    "        \"query_string\": query.replace(\"'\", '\"')\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = evaluator.evaluate_query_batch(queries, verbose=True, delay=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_totals = {\n",
    "    \"correct\": {\n",
    "        \"all\": 0,\n",
    "        \"simple\": 0,\n",
    "        \"medium\": 0,\n",
    "        \"complex\": 0\n",
    "    },\n",
    "    \"total\": {\n",
    "        \"all\": 0,\n",
    "        \"simple\": 0,\n",
    "        \"medium\": 0,\n",
    "        \"complex\": 0\n",
    "    }\n",
    "}\n",
    "for r in result:\n",
    "    complexity = r[\"complexity\"]\n",
    "    result_totals[\"total\"][\"all\"] += 1\n",
    "    result_totals[\"total\"][complexity] += 1\n",
    "    if r[\"correct\"]:\n",
    "        result_totals[\"correct\"][\"all\"] += 1\n",
    "        result_totals[\"correct\"][complexity] += 1\n",
    "\n",
    "def calculate_percentage(correct, total):\n",
    "    return (correct / total) * 100 if total != 0 else 0\n",
    "\n",
    "print(\"Results:\")\n",
    "for complexity in [\"all\", \"simple\", \"medium\", \"complex\"]:\n",
    "    correct = result_totals[\"correct\"][complexity]\n",
    "    total = result_totals[\"total\"][complexity]\n",
    "    percentage = calculate_percentage(correct, total)\n",
    "    print(f\"{complexity.capitalize():7s} - {correct:02d}/{total:02d} ({percentage:6.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"results_100/results_mondial_gpt35_100.json\", 'w') as f:\n",
    "    json.dump(result, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_filename = \"queries_mondial_gpt35_100_tokens.json\"\n",
    "with open(metadata_filename, 'r') as f:\n",
    "    metadata = json.load(f)\n",
    "\n",
    "total_time = 0\n",
    "for id in metadata.keys():\n",
    "    total_time += metadata[id][\"time_elapsed\"]\n",
    "\n",
    "time_per_query = total_time / len(metadata.keys())\n",
    "\n",
    "time_per_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
